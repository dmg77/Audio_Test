{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.models as models\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "HYPERPARAMETERS = {\n",
    "    \"n_components\": [2, 5, 10, 15],\n",
    "    \"covariance_type\": [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "}\n",
    "\n",
    "class GMMHyperModel(HyperModel):\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def build(self, hp):\n",
    "        # define the GMM model with hyperparameters\n",
    "        n_components = hp.Choice(\"n_components\", values=HYPERPARAMETERS[\"n_components\"])\n",
    "        covariance_type = hp.Choice(\"covariance_type\", values=HYPERPARAMETERS[\"covariance_type\"])\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type=covariance_type)\n",
    "        \n",
    "        # define the input layer for the mel spectrograms\n",
    "        inputs = tf.keras.layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # flatten the spectrograms to a 2D array for input to the GMM\n",
    "        flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "        \n",
    "        # connect the GMM to the input layer\n",
    "        outputs = gmm(flattened_inputs)\n",
    "        \n",
    "        # define the model with input and output layers\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a function to preprocess the audio files into mel spectrograms\n",
    "def preprocess_audio(file_path, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    # load the audio file\n",
    "    audio, sr = tf.audio.decode_wav(tf.io.read_file(file_path))\n",
    "    audio = tf.squeeze(audio, axis=1)\n",
    "    \n",
    "    # compute the mel spectrogram\n",
    "    stfts = tf.signal.stft(audio, frame_length=n_fft, frame_step=hop_length, pad_end=True)\n",
    "    magnitude_spectrograms = tf.abs(stfts)\n",
    "    num_spectrogram_bins = magnitude_spectrograms.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(n_mels, num_spectrogram_bins, sr, 0, sr/2)\n",
    "    mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms), linear_to_mel_weight_matrix)\n",
    "    mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    \n",
    "    # resize the spectrogram to the desired shape of (198, 32)\n",
    "    mel_spectrograms = tf.image.resize(mel_spectrograms, (198, 32))\n",
    "    \n",
    "    # normalize between 0 and 1\n",
    "    mel_spectrograms = (mel_spectrograms - tf.reduce_min(mel_spectrograms)) / (tf.reduce_max(mel_spectrograms) - tf.reduce_min(mel_spectrograms))\n",
    "    \n",
    "    # return the mel spectrogram\n",
    "    return mel_spectrograms.numpy()\n",
    "\n",
    "# define the training data\n",
    "audio_files = [...]\n",
    "spectrograms = np.array([preprocess_audio(file) for file in audio_files])\n",
    "\n",
    "# define the hypermodel and tuner\n",
    "hypermodel = GMMHyperModel(input_shape=spectrograms[0].shape)\n",
    "tuner = kt.Hyperband(hypermodel, objective=\"val_loss\", max_epochs=10, directory=\"tuner_dir\", project_name=\"gmm_tuner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the callbacks\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"gmm_best_model.h5\", monitor=\"val_loss\", save_best_only=True)\n",
    "\n",
    "compile the tuner\n",
    "tuner.search_space_summary()\n",
    "tuner.search(spectrograms, epochs=10, validation_split=0.2, callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "evaluate the best model on the validation set\n",
    "val_loss = best_model.evaluate(spectrograms, spectrograms, verbose=0)\n",
    "\n",
    "print(\"Best validation loss:\", val_loss)\n",
    "\n",
    "best_model.save(\"best_gmm_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
